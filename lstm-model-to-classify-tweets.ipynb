{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2231927,"sourceType":"datasetVersion","datasetId":1340873}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# mathematical operations-linear Algebra\nimport numpy as np \n\n# dataframe\nimport pandas as pd \n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n# Matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\n# NLTK\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nnltk.download('omw-1.4')\n\n# Word2vec\nimport gensim\nfrom gensim.test.utils import common_texts\nfrom gensim.models import Word2Vec\n\n# Utility\nimport string\nimport re\nimport numpy as np\nimport os\nfrom collections import Counter\nimport logging\nimport time\nimport pickle\nimport itertools\nimport random\nimport datetime\n\n# WordCloud\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter, defaultdict\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T07:50:31.296334Z","iopub.execute_input":"2024-04-12T07:50:31.296805Z","iopub.status.idle":"2024-04-12T07:50:31.752109Z","shell.execute_reply.started":"2024-04-12T07:50:31.296769Z","shell.execute_reply":"2024-04-12T07:50:31.750898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/twitter-sentiment-dataset/Twitter_Data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:56:44.507272Z","iopub.execute_input":"2024-04-12T06:56:44.508005Z","iopub.status.idle":"2024-04-12T06:56:44.958569Z","shell.execute_reply.started":"2024-04-12T06:56:44.507969Z","shell.execute_reply":"2024-04-12T06:56:44.957382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:56:46.99926Z","iopub.execute_input":"2024-04-12T06:56:46.999699Z","iopub.status.idle":"2024-04-12T06:56:47.017725Z","shell.execute_reply.started":"2024-04-12T06:56:46.999667Z","shell.execute_reply":"2024-04-12T06:56:47.016559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing","metadata":{}},{"cell_type":"code","source":"# Checking information about the dataset\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:56:49.853974Z","iopub.execute_input":"2024-04-12T06:56:49.854388Z","iopub.status.idle":"2024-04-12T06:56:49.898427Z","shell.execute_reply.started":"2024-04-12T06:56:49.854355Z","shell.execute_reply":"2024-04-12T06:56:49.897293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:57:28.71368Z","iopub.execute_input":"2024-04-12T06:57:28.714086Z","iopub.status.idle":"2024-04-12T06:57:28.744319Z","shell.execute_reply.started":"2024-04-12T06:57:28.714057Z","shell.execute_reply":"2024-04-12T06:57:28.743155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing values in the 'clean_text' column with empty strings\ndf['clean_text'].fillna('', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:58:04.647235Z","iopub.execute_input":"2024-04-12T06:58:04.648233Z","iopub.status.idle":"2024-04-12T06:58:04.682966Z","shell.execute_reply.started":"2024-04-12T06:58:04.648146Z","shell.execute_reply":"2024-04-12T06:58:04.681574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with missing values in the 'category' column\ndf.dropna(subset=['category'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:58:07.264604Z","iopub.execute_input":"2024-04-12T06:58:07.265023Z","iopub.status.idle":"2024-04-12T06:58:07.289858Z","shell.execute_reply.started":"2024-04-12T06:58:07.264988Z","shell.execute_reply":"2024-04-12T06:58:07.288517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirming the changes\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:58:10.032971Z","iopub.execute_input":"2024-04-12T06:58:10.034189Z","iopub.status.idle":"2024-04-12T06:58:10.063668Z","shell.execute_reply.started":"2024-04-12T06:58:10.034151Z","shell.execute_reply":"2024-04-12T06:58:10.06237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:58:13.332393Z","iopub.execute_input":"2024-04-12T06:58:13.333538Z","iopub.status.idle":"2024-04-12T06:58:13.460363Z","shell.execute_reply.started":"2024-04-12T06:58:13.333472Z","shell.execute_reply":"2024-04-12T06:58:13.459252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove duplicates\ndf.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:58:53.97244Z","iopub.execute_input":"2024-04-12T06:58:53.973563Z","iopub.status.idle":"2024-04-12T06:58:54.093897Z","shell.execute_reply.started":"2024-04-12T06:58:53.973525Z","shell.execute_reply":"2024-04-12T06:58:54.092608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Cloud Analysis","metadata":{}},{"cell_type":"code","source":"# Convert all tweets to a single string\nall_tweets = ' '.join(df['clean_text'])\n\n# Generate WordCloud\nwordcloud = WordCloud(width = 800, height = 800,\n                background_color ='white',\n                stopwords = set(STOPWORDS),\n                min_font_size = 10).generate(all_tweets)\n\n# Plot WordCloud                    \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:07:53.896854Z","iopub.execute_input":"2024-04-12T07:07:53.897269Z","iopub.status.idle":"2024-04-12T07:08:18.126653Z","shell.execute_reply.started":"2024-04-12T07:07:53.897227Z","shell.execute_reply":"2024-04-12T07:08:18.125539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word2Vec Analysis","metadata":{}},{"cell_type":"code","source":"# Tokenize words\ntokenized_text = [word_tokenize(text.lower()) for text in df['clean_text']]\n\n# Word2Vec model\nmodel = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n\n# Most similar words\nsimilar_words = model.wv.most_similar('happy', topn=5)\nprint(similar_words)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:17:39.844562Z","iopub.execute_input":"2024-04-12T07:17:39.845142Z","iopub.status.idle":"2024-04-12T07:18:50.443203Z","shell.execute_reply.started":"2024-04-12T07:17:39.845104Z","shell.execute_reply":"2024-04-12T07:18:50.441101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis using Deep-Learning Model--LSTM","metadata":{}},{"cell_type":"code","source":"# Define input and target variables\nX = df['clean_text']\ny = df['category']","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:19:47.109807Z","iopub.execute_input":"2024-04-12T07:19:47.110279Z","iopub.status.idle":"2024-04-12T07:19:47.116987Z","shell.execute_reply.started":"2024-04-12T07:19:47.110245Z","shell.execute_reply":"2024-04-12T07:19:47.115589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode target variable\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny = utils.to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:19:51.715073Z","iopub.execute_input":"2024-04-12T07:19:51.71579Z","iopub.status.idle":"2024-04-12T07:19:51.737679Z","shell.execute_reply.started":"2024-04-12T07:19:51.715755Z","shell.execute_reply":"2024-04-12T07:19:51.736417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:19:54.951116Z","iopub.execute_input":"2024-04-12T07:19:54.951593Z","iopub.status.idle":"2024-04-12T07:20:05.85304Z","shell.execute_reply.started":"2024-04-12T07:19:54.951555Z","shell.execute_reply":"2024-04-12T07:20:05.851734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vocabulary size\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:20:08.160256Z","iopub.execute_input":"2024-04-12T07:20:08.161101Z","iopub.status.idle":"2024-04-12T07:20:08.165919Z","shell.execute_reply.started":"2024-04-12T07:20:08.161062Z","shell.execute_reply":"2024-04-12T07:20:08.164717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Max sequence length\nmax_seq_length = max([len(seq) for seq in sequences])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:20:11.707103Z","iopub.execute_input":"2024-04-12T07:20:11.707559Z","iopub.status.idle":"2024-04-12T07:20:11.73739Z","shell.execute_reply.started":"2024-04-12T07:20:11.707515Z","shell.execute_reply":"2024-04-12T07:20:11.736127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pad sequences\nX_pad = pad_sequences(sequences, maxlen=max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:20:14.542839Z","iopub.execute_input":"2024-04-12T07:20:14.543787Z","iopub.status.idle":"2024-04-12T07:20:15.491083Z","shell.execute_reply.started":"2024-04-12T07:20:14.543742Z","shell.execute_reply":"2024-04-12T07:20:15.490042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:20:17.759081Z","iopub.execute_input":"2024-04-12T07:20:17.759542Z","iopub.status.idle":"2024-04-12T07:20:17.818363Z","shell.execute_reply.started":"2024-04-12T07:20:17.759492Z","shell.execute_reply":"2024-04-12T07:20:17.817285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define LSTM model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=100, input_shape=(max_seq_length,)))\nmodel.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(units=3, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:24:15.519287Z","iopub.execute_input":"2024-04-12T07:24:15.520061Z","iopub.status.idle":"2024-04-12T07:24:15.697335Z","shell.execute_reply.started":"2024-04-12T07:24:15.520024Z","shell.execute_reply":"2024-04-12T07:24:15.695964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:24:20.473736Z","iopub.execute_input":"2024-04-12T07:24:20.474171Z","iopub.status.idle":"2024-04-12T07:24:20.485802Z","shell.execute_reply.started":"2024-04-12T07:24:20.47413Z","shell.execute_reply":"2024-04-12T07:24:20.484443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model summary\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:24:23.311324Z","iopub.execute_input":"2024-04-12T07:24:23.311767Z","iopub.status.idle":"2024-04-12T07:24:23.337334Z","shell.execute_reply.started":"2024-04-12T07:24:23.311734Z","shell.execute_reply":"2024-04-12T07:24:23.335976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The first column lists the types of layers in the model (Embedding, LSTM, Dense).\n* The second column shows the output shape of each layer. For the Embedding layer, (None, 52, 100) indicates that the output shape is (batch_size, input_length, output_dim), where batch_size is None because it can vary, input_length is 52, and output_dim is 100. For the LSTM layer, (None, 128) indicates that the output shape is (batch_size, units) where units is 128. For the Dense layer, (None, 3) indicates that the output shape is (batch_size, number_of_classes), where number_of_classes is 3 in this case.\n* The third column shows the number of parameters in each layer. For the Embedding layer, it has 11,367,900 parameters, which is calculated as vocab_size * output_dim. For the LSTM layer, it has 117,248 parameters, and for the Dense layer, it has 387 parameters.\n* The summary also provides information about the total number of parameters in the model (Total params) and the number of trainable parameters (Trainable params). In this case, all parameters are trainable.","metadata":{}},{"cell_type":"code","source":"# Define callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:25:33.649619Z","iopub.execute_input":"2024-04-12T07:25:33.65043Z","iopub.status.idle":"2024-04-12T07:25:33.656114Z","shell.execute_reply.started":"2024-04-12T07:25:33.650392Z","shell.execute_reply":"2024-04-12T07:25:33.654948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.1, callbacks=[reduce_lr, early_stop])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:25:36.669988Z","iopub.execute_input":"2024-04-12T07:25:36.670455Z","iopub.status.idle":"2024-04-12T07:44:52.75904Z","shell.execute_reply.started":"2024-04-12T07:25:36.670395Z","shell.execute_reply":"2024-04-12T07:44:52.757595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:45:54.613955Z","iopub.execute_input":"2024-04-12T07:45:54.614443Z","iopub.status.idle":"2024-04-12T07:46:35.655359Z","shell.execute_reply.started":"2024-04-12T07:45:54.614405Z","shell.execute_reply":"2024-04-12T07:46:35.654126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n\n# Plot training and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\n# Plot training and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:48:06.245026Z","iopub.execute_input":"2024-04-12T07:48:06.245563Z","iopub.status.idle":"2024-04-12T07:48:06.816786Z","shell.execute_reply.started":"2024-04-12T07:48:06.245526Z","shell.execute_reply":"2024-04-12T07:48:06.815568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Model Prediction","metadata":{}},{"cell_type":"code","source":"# Make predictions on the test data\npredictions = model.predict(X_test)\n\n# Convert predictions to class labels\npredicted_labels = np.argmax(predictions, axis=1)\n\n# Convert one-hot encoded labels to original labels\ntrue_labels = np.argmax(y_test, axis=1)\n\n# Print some examples of predicted and true labels\nprint(\"Examples of Predictions vs True Labels:\")\nfor i in range(5):\n    print(\"Predicted:\", predicted_labels[i], \"True:\", true_labels[i])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:48:13.965685Z","iopub.execute_input":"2024-04-12T07:48:13.96611Z","iopub.status.idle":"2024-04-12T07:48:38.52735Z","shell.execute_reply.started":"2024-04-12T07:48:13.966077Z","shell.execute_reply":"2024-04-12T07:48:38.526115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test our Model","metadata":{}},{"cell_type":"code","source":"# Define a function to classify sentiment\ndef classify_sentiment(text):\n    # Preprocess the text (tokenization, padding, etc.)\n    text_sequence = tokenizer.texts_to_sequences([text])\n    padded_sequence = pad_sequences(text_sequence, maxlen=max_seq_length)\n    \n    # Make prediction using the trained model\n    prediction = model.predict(padded_sequence)\n    \n    # Convert prediction to class label\n    predicted_label = np.argmax(prediction)\n    \n    # Map class label to sentiment\n    sentiment_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n    sentiment = sentiment_mapping[predicted_label]\n    \n    return sentiment\n\n# Test the function with somesentences\nsentences = [\n    \"I love this movie, it's amazing!\",\n    \"The weather today is beautiful.\",\n    \"I feel happy when I'm with my friends.\",\n    \"The food at this restaurant is delicious.\",\n    \"I'm excited about the new project at work.\",\n    \"I'm not sure if I like the new design.\",\n    \"I'm feeling a bit down today.\",\n    \"This book is boring, I couldn't finish it.\",\n    \"The customer service was terrible, I won't go back.\",\n    \"I'm so angry right now!\",\n    \"I'm indifferent about the outcome of the game.\",\n    \"The traffic was horrible this morning.\",\n    \"I'm grateful for all the help you've given me.\",\n    \"I'm feeling anxious about the presentation tomorrow.\",\n    \"The movie was okay, nothing special.\",\n]\n\nprint(\"Sentences and Predicted Sentiments:\")\nfor sentence in sentences:\n    sentiment = classify_sentiment(sentence)\n    print(\"Sentence:\", sentence)\n    print(\"Predicted Sentiment:\", sentiment)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:48:58.322885Z","iopub.execute_input":"2024-04-12T07:48:58.323365Z","iopub.status.idle":"2024-04-12T07:48:59.719738Z","shell.execute_reply.started":"2024-04-12T07:48:58.323326Z","shell.execute_reply":"2024-04-12T07:48:59.718453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Make predictions on the entire test set\npredictions = model.predict(X_test)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(y_test, axis=1)\n\n# Compute confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:50:39.668063Z","iopub.execute_input":"2024-04-12T07:50:39.668519Z","iopub.status.idle":"2024-04-12T07:51:02.911908Z","shell.execute_reply.started":"2024-04-12T07:50:39.668468Z","shell.execute_reply":"2024-04-12T07:51:02.910697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# classification report","metadata":{}},{"cell_type":"code","source":"# Classification report\nprint(\"Classification Report:\")\nprint(classification_report(true_labels, predicted_labels, target_names=['Negative', 'Neutral', 'Positive']))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T07:51:14.02376Z","iopub.execute_input":"2024-04-12T07:51:14.02416Z","iopub.status.idle":"2024-04-12T07:51:14.093179Z","shell.execute_reply.started":"2024-04-12T07:51:14.024131Z","shell.execute_reply":"2024-04-12T07:51:14.091924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Interpretability (Attention Mechanism)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deployment","metadata":{}}]}